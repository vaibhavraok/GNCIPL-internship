from __future__ import annotations
import os
import re
import sys
import argparse
import logging
from typing import List, Tuple

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

import torch
from transformers import pipeline, set_seed


LOGGER = logging.getLogger("ecom-gpt2")
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s",
    datefmt="%H:%M:%S",
)


def load_dataset(path: str) -> pd.DataFrame:
    if not os.path.exists(path):
        LOGGER.error("Dataset not found: %s", path)
        raise FileNotFoundError(f"Dataset not found: {path}")
    df = pd.read_csv(path)
    LOGGER.info("Dataset loaded | rows=%d, cols=%d", *df.shape)
    LOGGER.info("Columns: %s", list(df.columns))
    return df

def ensure_dir(path: str) -> None:
    os.makedirs(path, exist_ok=True)
    LOGGER.info("Using folder: %s", path)

def plot_category_distribution(df: pd.DataFrame, out_dir: str) -> Tuple[bool, str | None]:
    if "Category" not in df.columns:
        LOGGER.warning("Skipped Category plot (column 'Category' not found)")
        return False, None

    plt.figure(figsize=(8, 5))
    sns.countplot(x="Category", data=df)
    plt.title("Product Category Distribution")
    plt.xticks(rotation=30)
    plt.tight_layout()
    out = os.path.join(out_dir, "category_distribution.png")
    plt.savefig(out, dpi=150)
    plt.close()
    LOGGER.info("Saved: %s", out)
    return True, out


def plot_region_revenue(df: pd.DataFrame, out_dir: str) -> Tuple[bool, str | None]:
    needed = {"Region", "Revenue"}
    if not needed.issubset(df.columns):
        LOGGER.warning("Skipped Region-Revenue plot (need columns %s)", needed)
        return False, None

    revenue = pd.to_numeric(df["Revenue"], errors="coerce")
    grp = df.assign(Revenue=revenue).dropna(subset=["Revenue"]).groupby("Region")["Revenue"].sum().sort_values()

    plt.figure(figsize=(8, 5))
    sns.barplot(x=grp.index, y=grp.values)
    plt.title("Region-wise Revenue")
    plt.xticks(rotation=30)
    plt.ylabel("Total Revenue")
    plt.tight_layout()
    out = os.path.join(out_dir, "region_revenue.png")
    plt.savefig(out, dpi=150)
    plt.close()
    LOGGER.info("Saved: %s", out)
    return True, out

def read_prompts_file(path: str) -> List[str]:
    with open(path, "r", encoding="utf-8") as f:
        lines = [ln.strip() for ln in f.readlines()]
    prompts = [ln for ln in lines if ln and not ln.startswith("#")]
    if not prompts:
        raise ValueError("Prompts file is empty after filtering comments/blank lines.")
    return prompts


def build_prompts_from_dataset(df: pd.DataFrame, limit: int = 20) -> List[str]:
    prompts: List[str] = []
    name_col = next((c for c in ["ProductName", "Product", "Item", "Title"] if c in df.columns), None)
    cat_col = "Category" if "Category" in df.columns else None
    brand_col = next((c for c in ["Brand", "Manufacturer"] if c in df.columns), None)

    sample_df = df.copy()
    if name_col:
        sample_df = sample_df.drop_duplicates(subset=[name_col])

    sample_df = sample_df.head(max(5, min(limit, len(sample_df))))

    for _, row in sample_df.iterrows():
        name = str(row[name_col]) if name_col else "the product"
        cat = str(row[cat_col]) if cat_col else "product"
        brand = str(row[brand_col]) if brand_col else ""
        brand_txt = f" by {brand}" if brand else ""
        prompts.append(
            f"Write a concise customer review (2-4 sentences) for a {cat} named '{name}'{brand_txt}. Mention one strength and one thing to improve:"
        )

    if not prompts:
        prompts = [
            "Write a short customer review for a smartphone with excellent battery life:",
            "Generate a customer review for an online clothing store with fast delivery:",
            "Write a customer review for a laptop with heating issues but strong overall performance:",
        ]
    return prompts


DEFAULT_PROMPTS = [
    "Write a short customer review for a smartphone with excellent battery life:",
    "Generate a customer review for an online clothing store with fast delivery:",
    "Write a customer review for a laptop with heating issues but strong overall performance:",
]

TOKEN_CLEAN_RE = re.compile(r"\s+|<\|endoftext\|>")
SENT_SPLIT_RE = re.compile(r"(?<=[.!?])\s+")


def init_generator(model_name: str, use_cpu: bool, seed: int):
    set_seed(seed)
    if not use_cpu and torch.cuda.is_available():
        device_idx = 0
        LOGGER.info("Using GPU for generation (device 0)")
        model_kwargs = {"torch_dtype": torch.float16}
    else:
        device_idx = -1
        LOGGER.info("Using CPU for generation")
        model_kwargs = {}

    try:
        gen = pipeline(
            "text-generation",
            model=model_name,
            device=device_idx,
            model_kwargs=model_kwargs,
        )
        pad_id = gen.tokenizer.eos_token_id
        if gen.tokenizer.pad_token_id is None:
            gen.tokenizer.pad_token = gen.tokenizer.eos_token
            gen.tokenizer.pad_token_id = pad_id
        return gen
    except RuntimeError as e:
        LOGGER.warning("Model '%s' failed to load (%s). Falling back to 'distilgpt2'.", model_name, e)
        gen = pipeline("text-generation", model="distilgpt2", device=device_idx)
        pad_id = gen.tokenizer.eos_token_id
        if gen.tokenizer.pad_token_id is None:
            gen.tokenizer.pad_token = gen.tokenizer.eos_token
            gen.tokenizer.pad_token_id = pad_id
        return gen


def _clean_review(prompt: str, text: str) -> str:
    cleaned = text.replace(prompt, "")
    cleaned = TOKEN_CLEAN_RE.sub(" ", cleaned).strip()
    return cleaned


def _truncate_sentences(text: str, max_sentences: int = 4) -> str:
    sentences = SENT_SPLIT_RE.split(text.strip())
    return " ".join(sentences[:max_sentences]).strip()


def generate_reviews(
    prompts: List[str],
    generator,
    max_new_tokens: int = 90,
    temperature: float = 0.8,
    top_p: float = 0.95,
) -> pd.DataFrame:
    results = []
    pad_id = generator.tokenizer.pad_token_id or generator.tokenizer.eos_token_id

    for i, prompt in enumerate(prompts, start=1):
        try:
            out = generator(
                prompt,
                max_new_tokens=max_new_tokens,
                do_sample=True,
                temperature=temperature,
                top_p=top_p,
                pad_token_id=pad_id,
                eos_token_id=pad_id,
                num_return_sequences=1,
            )[0]["generated_text"]
            review = _truncate_sentences(_clean_review(prompt, out), max_sentences=4)
            results.append({"idx": i, "prompt": prompt, "review": review})
            LOGGER.info("Generated review %d", i)
        except Exception as e:
            LOGGER.error("Generation failed for prompt %d: %s", i, e)
            results.append({"idx": i, "prompt": prompt, "review": "<generation failed>"})

    return pd.DataFrame(results)

def save_reviews_csv(df: pd.DataFrame, path: str) -> None:
    df.to_csv(path, index=False)
    LOGGER.info("Reviews saved to: %s", path)


def write_summary(df: pd.DataFrame, out_dir: str) -> str:
    lines = []
    lines.append(f"Rows: {df.shape[0]}, Cols: {df.shape[1]}")
    if "Category" in df.columns:
        top_cats = df["Category"].value_counts().head(5).to_dict()
        lines.append(f"Top categories: {top_cats}")
    if {"Region", "Revenue"}.issubset(df.columns):
        rev = pd.to_numeric(df["Revenue"], errors="coerce").dropna()
        if not rev.empty:
            lines.append(f"Revenue: sum={rev.sum():.2f}, mean={rev.mean():.2f}, median={rev.median():.2f}")
    text = "\n".join(lines)
    path = os.path.join(out_dir, "dataset_summary.txt")
    with open(path, "w", encoding="utf-8") as f:
        f.write(text + "\n")
    LOGGER.info("Summary saved: %s", path)
    return path


def parse_args() -> argparse.Namespace:
    p = argparse.ArgumentParser(description="Generate plots and GPT-2 reviews from an e-commerce CSV.")
    p.add_argument("--input-csv", default="synthetic_ecom_customers_gpt2.csv", help="Path to input dataset CSV")
    p.add_argument("--plots-dir", default="plots", help="Directory to save plots")
    p.add_argument("--reviews-csv", default="generated_reviews_gpt2.csv", help="Output CSV for generated reviews")

    p.add_argument("--prompts-file", default=None, help="Text file with one prompt per line")
    p.add_argument("--from-dataset", action="store_true", help="Build prompts using dataset columns if present")
    p.add_argument("--num-reviews", type=int, default=None, help="Number of reviews to generate (cycles through prompts if needed)")

    p.add_argument("--model-name", default="gpt2", help="HF model name (e.g., gpt2, distilgpt2)")
    p.add_argument("--max-new-tokens", type=int, default=90)
    p.add_argument("--temperature", type=float, default=0.8)
    p.add_argument("--top-p", type=float, default=0.95)
    p.add_argument("--seed", type=int, default=42)
    p.add_argument("--cpu", action="store_true", help="Force CPU even if GPU is available")
    return p.parse_args()


def maybe_expand_prompts(prompts: List[str], target_n: int | None) -> List[str]:
    if target_n is None or target_n <= 0:
        return prompts
    if len(prompts) >= target_n:
        return prompts[:target_n]
    out: List[str] = []
    i = 0
    while len(out) < target_n:
        out.append(prompts[i % len(prompts)])
        i += 1
    return out


def main():
    args = parse_args()

    df = load_dataset(args.input_csv)

    ensure_dir(args.plots_dir)

    plot_category_distribution(df, args.plots_dir)
    plot_region_revenue(df, args.plots_dir)
    write_summary(df, args.plots_dir)
    LOGGER.info("Graphs step complete. Files saved inside '%s'", args.plots_dir)

    if args.prompts_file:
        prompts = read_prompts_file(args.prompts_file)
        LOGGER.info("Loaded %d prompts from file", len(prompts))
    elif args.from_dataset:
        prompts = build_prompts_from_dataset(df, limit=50)
        LOGGER.info("Built %d prompts from dataset", len(prompts))
    else:
        prompts = DEFAULT_PROMPTS
        LOGGER.info("Using %d default prompts", len(prompts))

    prompts = maybe_expand_prompts(prompts, args.num_reviews)

    generator = init_generator(args.model_name, use_cpu=args.cpu, seed=args.seed)
    reviews_df = generate_reviews(
        prompts,
        generator,
        max_new_tokens=args.max_new_tokens,
        temperature=args.temperature,
        top_p=args.top_p,
    )

    head_n = min(5, len(reviews_df))
    LOGGER.info("\n===== Generated Reviews (Preview: %d) =====", head_n)
    for _, row in reviews_df.head(head_n).iterrows():
        LOGGER.info("- Prompt: %s\n  Review: %s\n", row["prompt"], row["review"]) 

    save_reviews_csv(reviews_df, args.reviews_csv)
    LOGGER.info("All steps completed successfully!")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        LOGGER.error("Interrupted by user.")
        sys.exit(130)
    except Exception as e:
        LOGGER.exception("Fatal error: %s", e)
        sys.exit(1)

